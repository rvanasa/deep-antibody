{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "antibody-data-collection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvanasa/deep-antibody/blob/master/antibody_data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEyGK1AoVCW_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Workspace setup\n",
        "\n",
        "!pip install -q biopython pdb-tools\n",
        "!wget -nc ftp://ftp.cmbi.ru.nl/pub/software/dssp/dssp-2.0.4-linux-amd64 -O /usr/local/bin/dssp && chmod +x /usr/local/bin/dssp\n",
        "\n",
        "from IPython.display import clear_output, display\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import Bio\n",
        "import Bio.PDB\n",
        "from Bio.PDB import DSSP\n",
        "\n",
        "contact_buffer = 4\n",
        "contact_window_size = contact_buffer * 2 + 1\n",
        "\n",
        "amino_acids = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'GLU', 'GLN', 'GLY', 'HIS', 'ILE', 'LEU', 'LYS', 'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL', '???']\n",
        "oneletters = 'ARNDCEQGHILKMFPSTWYV'\n",
        "ssletters = 'HBEGITS'\n",
        "\n",
        "parser = Bio.PDB.PDBParser(get_header=True)\n",
        "\n",
        "def parse(ident):\n",
        "  if '.' not in ident:\n",
        "    filename = f'{ident}.pdb'\n",
        "    !wget -nc https://files.rcsb.org/download/{ident}.pdb\n",
        "  else:\n",
        "    filename = ident\n",
        "  return parser.get_structure(ident, filename)\n",
        "\n",
        "\n",
        "def run_dssp(filename):\n",
        "  structure = parse(filename)\n",
        "  adfs = []\n",
        "  for model in structure.get_models():\n",
        "    chain_info = []\n",
        "    for chain in model.get_chains():\n",
        "      chain_info += [(chain.id, i - 1, create_seq([r.resname])) for i, r in enumerate(chain)]\n",
        "    \n",
        "    dssp = DSSP(structure[0], filename)\n",
        "    rows = [(c, i, rc.strip() or '-', *v) for (c, (_, i, rc)), v in dssp.property_dict.items()]\n",
        "\n",
        "    dfs = pd.DataFrame(rows, columns=[\n",
        "        'Key', 'Num', 'Sub',\n",
        "        'DSSP Index', 'Residue',\n",
        "        'SS', 'ASA', 'Phi', 'Psi',\n",
        "        'NH->O_1_relidx', 'NH->O_1_energy',\n",
        "        'O->NH_1_relidx', 'O->NH_1_energy',\n",
        "        'NH->O_2_relidx', 'NH->O_2_energy',\n",
        "        'O->NH_2_relidx', 'O->NH_2_energy'])\n",
        "    \n",
        "    dfs.insert(0, 'Model', model.id)\n",
        "    adfs.append(dfs)\n",
        "  \n",
        "  return pd.concat(adfs)\n",
        "\n",
        "\n",
        "def create_seq(rs):\n",
        "  return ''.join(oneletters[amino_acids.index(r)] if r in amino_acids else 'X' for r in rs)\n",
        "\n",
        "\n",
        "def cmd(command):\n",
        "  if not isinstance(command, str):\n",
        "    for c in command:\n",
        "      cmd(c)\n",
        "  if os.system(command):\n",
        "    raise Exception(f'Non-zero exit code in command: $ {command}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc7hX1toEGCY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title SAbDab caching\n",
        "\n",
        "!wget -nc -O sab_summary_all.tsv http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/summary/all/\n",
        "!wget -nc -O sab_all.zip http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/archive/all/\n",
        "!unzip -q -n sab_all.zip\n",
        "!rm -rf __MACOSX\n",
        "clear_output()\n",
        "\n",
        "pdb_dirname = './all_structures/raw'\n",
        "pdb_files = os.listdir(pdb_dirname)\n",
        "\n",
        "dfm = pd.read_csv('sab_summary_all.tsv', sep='\\t')\n",
        "dfm['file'] = dfm.pdb.map(lambda p: p + '.pdb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Ay7tIU8cp0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Chain parsing\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in pdb_files:\n",
        "  structure = parse(f'{pdb_dirname}/{file}')\n",
        "  for model in structure.get_models():\n",
        "    chains = list(model.get_chains())\n",
        "\n",
        "    for chain in chains:\n",
        "      data.append({\n",
        "          'File': file,\n",
        "          'Model': model.id,\n",
        "          'Key': chain.id,\n",
        "          'Sequence': ','.join(r.resname for r in chain),\n",
        "      })\n",
        "\n",
        "    # print(file, [{chain.id: len(chain)} for chain in chains])\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df['Compact'] = df.Sequence.map(lambda rs: create_seq(rs.split(',')))\n",
        "df[['File', 'Model', 'Key', 'Sequence']].to_csv('docked_seqs.csv', index=False)\n",
        "df[['File', 'Model', 'Key', 'Compact']].to_csv('docked_oneletters.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E61Dc_J9HXdh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Chain preprocessing\n",
        "\n",
        "dfc = pd.read_csv('docked_oneletters.csv')\n",
        "dfc.Compact = dfc.Compact.str.strip('X')\n",
        "dfc = dfc[~dfc.Compact.str.contains('X')]\n",
        "dfc = dfc[dfc.Compact.str.len() > 0]\n",
        "dfc = dfc.dropna()\n",
        "\n",
        "data = []\n",
        "for i, row in dfm.iterrows():\n",
        "  if not pd.notnull(row.antigen_chain):\n",
        "    continue\n",
        "\n",
        "  dfc_rel = dfc[(dfc.File == row.file) & (dfc.Model == row.model)].set_index('Key')\n",
        "\n",
        "  achains = [ak.strip() or '-' for ak in row.antigen_chain.split('|')]\n",
        "\n",
        "  lk = row.Lchain if pd.notnull(row.Lchain) else '-'\n",
        "  hk = row.Hchain if pd.notnull(row.Hchain) else'-'\n",
        "\n",
        "  L = dfc_rel.loc[lk].Compact if lk in dfc_rel.index else '-'\n",
        "  H = dfc_rel.loc[hk].Compact if hk in dfc_rel.index else '-'\n",
        "\n",
        "  if H == '-' and L == '-':\n",
        "    continue\n",
        "\n",
        "  for ak in achains:\n",
        "    A = dfc_rel.loc[ak].Compact if ak in dfc_rel.index else '-'\n",
        "\n",
        "    data.append(dict(\n",
        "        File=row.file,\n",
        "        Model=row.model,\n",
        "        LKey=lk,\n",
        "        HKey=hk,\n",
        "        AKey=ak,\n",
        "        Light=L,\n",
        "        Heavy=H,\n",
        "        Antigen=A,\n",
        "    ))\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates(['Light', 'Heavy', 'Antigen']) ##TODO drop by resolution\n",
        "df = df.sort_values(['File', 'Model'])\n",
        "df.to_csv('docked_preprocessed.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcpSPv6phrXp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Contact point calculation\n",
        "\n",
        "import numpy.linalg as lin\n",
        "\n",
        "df = pd.read_csv('docked_preprocessed.csv')\n",
        "\n",
        "contact_dist_threshold = 4\n",
        "\n",
        "def append_contact_point():\n",
        "  global data, ct\n",
        "  ct += 1\n",
        "  data.append({\n",
        "      'File': filename,\n",
        "      'Model': model.id,\n",
        "      'BType': btype,\n",
        "      'BKey': cb.id,\n",
        "      'BIndex': y,\n",
        "      'BResidue': rlb[y].resname,\n",
        "      'AKey': ca.id,\n",
        "      'AIndex': x,\n",
        "      'AResidue': rla[x].resname,\n",
        "  })\n",
        "\n",
        "data = []\n",
        "for filename, dff in df.groupby('File'):\n",
        "  structure = parse(f'{pdb_dirname}/{filename}')\n",
        "  \n",
        "  models = list(structure.get_models())\n",
        "\n",
        "  for i, row in dff.iterrows():\n",
        "    model = models[row.Model]\n",
        "    chain_map = {chain.id: chain for chain in model.get_chains()}\n",
        "\n",
        "    H = chain_map.get(row.HKey)\n",
        "    L = chain_map.get(row.LKey)\n",
        "    A = chain_map.get(row.AKey)\n",
        "\n",
        "    if A is None:\n",
        "      continue\n",
        "\n",
        "    print()\n",
        "    # print('>>', filename, model.id, [c.id for c in chains])\n",
        "    \n",
        "    ca = A\n",
        "    for btype, cb in (('H', H), ('L', L)):\n",
        "      if cb is None:\n",
        "        continue\n",
        "      \n",
        "      rla = list(ca)\n",
        "      rlb = list(cb)\n",
        "\n",
        "      rxa = [[a.coord for a in r] for r in rla]\n",
        "      rxb = [[a.coord for a in r] for r in rlb]\n",
        "\n",
        "      mx = max(*(len(x) for x in rxa), *(len(x) for x in rxb))\n",
        "      ct = 0\n",
        "\n",
        "      size = len(rxa) * len(rxb) * mx ** 2\n",
        "      if size > 1e8:\n",
        "        print('Using low memory variant')\n",
        "        \n",
        "        for x, xa in enumerate(rxa):\n",
        "          xa = np.array(xa)\n",
        "          for y, xb in enumerate(rxb):\n",
        "            norms = lin.norm(xa[:, None] - xb, axis=2)\n",
        "            if np.any((norms != 0) & (norms <= contact_dist_threshold)):\n",
        "              append_contact_point()\n",
        "      else:\n",
        "        axa = np.zeros((len(rxa) * mx, 3))\n",
        "        axb = np.zeros((len(rxb) * mx, 3))\n",
        "\n",
        "        for i, x in enumerate(rxa):\n",
        "          axa[i * mx:i * mx + len(x)] = x\n",
        "        for i, x in enumerate(rxb):\n",
        "          axb[i * mx:i * mx + len(x)] = x\n",
        "\n",
        "        norms = lin.norm(axa[:, None] - axb, axis=2)\n",
        "        locs = np.argwhere((norms != 0) & (norms <= contact_dist_threshold)) // mx\n",
        "        if len(locs):\n",
        "          for x, y in np.unique(locs, axis=0):\n",
        "            append_contact_point()\n",
        "      \n",
        "      print(row.File, ct)\n",
        "\n",
        "clear_output()\n",
        "dfx = pd.DataFrame(data)\n",
        "dfx.to_csv('chain_contacts.csv', index=False)\n",
        "dfx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzXiqvExkYZi",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Contact point preprocessing\n",
        "\n",
        "dfo = pd.read_csv('docked_oneletters.csv')\n",
        "dfp = pd.read_csv('docked_preprocessed.csv')\n",
        "dfx = pd.read_csv('chain_contacts.csv')\n",
        "\n",
        "df = dfx.merge(dfp, on=['File', 'Model', 'AKey'])\n",
        "\n",
        "for col in ('Antigen', 'Heavy', 'Light'):\n",
        "  ckey = col[0] + 'Key'\n",
        "  df = df.drop(columns=col).merge(dfo.rename(columns={'Key': ckey}), on=['File', 'Model', ckey]).rename(columns={'Compact': col})\n",
        "\n",
        "df['BWindow'] = df.apply(\n",
        "    lambda x: (x.Heavy if x.BType == 'H' else x.Light)[x.BIndex - contact_buffer:x.BIndex + contact_buffer + 1],\n",
        "    axis=1)\n",
        "df['AWindow'] = df.apply(\n",
        "    lambda x: x.Antigen[x.AIndex - contact_buffer:x.AIndex + contact_buffer + 1],\n",
        "    axis=1)\n",
        "\n",
        "dfs = df.drop(columns=['Antigen', 'Light', 'Heavy'])\n",
        "dfs = dfs.dropna()\n",
        "dfs.to_csv('contacts_preprocessed.csv', index=False)\n",
        "dfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEdQs9ix7Zqp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Contact point refinement\n",
        "\n",
        "df = pd.read_csv('contacts_preprocessed.csv')\n",
        "df = df[(df.BWindow.str.len() == contact_window_size) & (df.AWindow.str.len() == contact_window_size)]\n",
        "df = df[~df.BWindow.str.contains('X') & ~df.AWindow.str.contains('X')]\n",
        "df.to_csv('contacts_filtered.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdlYe9Q5whDR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Secondary structure calculation\n",
        "\n",
        "df = pd.read_csv('docked_preprocessed.csv')\n",
        "\n",
        "p_dfs = None\n",
        "files = sorted(set(df.File))\n",
        "for file in files:\n",
        "  print(file)\n",
        "  try:\n",
        "    dfs = run_dssp(f'{pdb_dirname}/{file}')\n",
        "    dfs.insert(0, 'File', file)\n",
        "    p_dfs = p_dfs.append(dfs) if p_dfs is not None else dfs\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "clear_output()\n",
        "p_dfs.to_csv('dssp_residues.csv', index=False)\n",
        "p_dfs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U_atqwtkfP-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Primary / secondary structure coalescence\n",
        "\n",
        "dfs = pd.read_csv('dssp_residues.csv')\n",
        "\n",
        "dfd = pd.read_csv('docked_oneletters.csv')\n",
        "dfd['Compact'] = dfd.Compact.str.strip('X')\n",
        "dfd = dfd[~dfd.Compact.str.contains('X')]\n",
        "# dfd = dfd.set_index(['File', 'Model', 'Key'])\n",
        "\n",
        "nskipped = 0\n",
        "\n",
        "data = []\n",
        "for (file, mid, key), secondary in dfs.groupby(['File', 'Model', 'Key']):\n",
        "  # print(file)##\n",
        "\n",
        "  dfdr = dfd[(dfd.File == file) & (dfd.Model == model) & (dfd.Key == key)]\n",
        "  if len(dfdr) != 1:\n",
        "    print(f'{len(dfdr)} candidates for {key} in model {model}')\n",
        "    nskipped += 1\n",
        "    continue\n",
        "\n",
        "  seq = dfdr.iloc[0].Compact\n",
        "\n",
        "  # print(seq)\n",
        "  # print(''.join(secondary.Residue))\n",
        "\n",
        "  if seq != ''.join(secondary.Residue):\n",
        "    print(f'Residue mismatch for {file}')\n",
        "    # print(seq)#\n",
        "    # print(''.join(secondary.Residue))#\n",
        "    nskipped += 1\n",
        "    continue\n",
        "  \n",
        "  data.append(dict(\n",
        "      File=file,\n",
        "      Model=mid,\n",
        "      Key=key,\n",
        "      Compact=seq,\n",
        "      SS='|'.join(secondary.SS),\n",
        "      ASA='|'.join(str(round(f, 6)) for f in secondary.ASA),\n",
        "      Phi='|'.join(str(round(f, 6)) for f in secondary.Phi),\n",
        "      Psi='|'.join(str(round(f, 6)) for f in secondary.Psi),\n",
        "  ))\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('docked_secondary.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io2uxu11f5_1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ANARCI installation\n",
        "\n",
        "!apt install hmmer\n",
        "!tar xkf anarci-1.3.tar.gz\n",
        "cmd('cd anarci-1.3/ && python2 setup.py install')\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h_te9hojHrr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Sequence numbering\n",
        "\n",
        "%%python2\n",
        "\n",
        "from IPython.display import clear_output, display\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "import anarci as an\n",
        "\n",
        "options = dict(\n",
        "    scheme='martin',\n",
        "    assign_germline=True,\n",
        "    allowed_species='human'))\n",
        "\n",
        "type_map = dict(H='heavy', L='light')\n",
        "\n",
        "df = pd.read_csv('docked_preprocessed.csv')\n",
        "\n",
        "adfr = []\n",
        "adfa = []\n",
        "adft = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "  filename = row.File\n",
        "  mid = row.Model\n",
        "  for key, seq, btype in [(row.HKey, row.Heavy, 'H'), (row.LKey, row.Light, 'L')]:\n",
        "    seqs = [(key, seq)]\n",
        "    \n",
        "    # print filename[:-4], mid, key\n",
        "\n",
        "    results = list(zip(*an.run_anarci(seqs, allow=type_map[btype], **options)))\n",
        "    if any(not ns for _, ns, _, _ in results):\n",
        "      results = list(zip(*an.run_anarci(seqs, allow='ig', **options)))\n",
        "    if any(not ns for _, ns, _, _ in results):\n",
        "      results = list(zip(*an.run_anarci(seqs, **options)))\n",
        "\n",
        "    for (key, seq), numbers, alignments, hit_tables in results:\n",
        "\n",
        "      if numbers:\n",
        "        dfr = pd.DataFrame(dict(\n",
        "            Res=res,\n",
        "            Num=num,\n",
        "            Sub=sub.strip() or '-',\n",
        "        ) for i, (residues, start, end) in enumerate(numbers) for (num, sub), res in residues)\n",
        "        dfr.insert(0, 'File', filename)\n",
        "        dfr.insert(1, 'Model', mid)\n",
        "        dfr.insert(2, 'Key', key)\n",
        "        dfr.insert(3, 'Type', btype)\n",
        "        adfr.append(dfr)\n",
        "\n",
        "      if alignments:\n",
        "        dfa = pd.DataFrame(alignments)\n",
        "        dfa.insert(0, 'File', filename)\n",
        "        dfa.insert(1, 'Model', mid)\n",
        "        adfa.append(dfa)\n",
        "\n",
        "      if hit_tables:\n",
        "        dft = pd.DataFrame(hit_tables[1:], columns=hit_tables[0])\n",
        "        dft.insert(0, 'File', filename)\n",
        "        dft.insert(1, 'Model', mid)\n",
        "        dft.insert(2, 'Key', key)\n",
        "        dft.insert(3, 'Type', btype)\n",
        "        adft.append(dft)\n",
        "\n",
        "clear_output()\n",
        "pd.concat(adfr).to_csv('anarci_residues.csv', index=False)\n",
        "pd.concat(adfa).to_csv('anarci_alignments.csv', index=False)\n",
        "pd.concat(adft).to_csv('anarci_hit_tables.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcNfloxB6isJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title CDR extraction\n",
        "\n",
        "def cdr_range(df, btype, start, end):\n",
        "  return (df.Type == btype) & (df.Num >= start) & (df.Num <= end)\n",
        "\n",
        "df = pd.read_csv('anarci_residues.csv')\n",
        "df['CDR'] = '-'\n",
        "\n",
        "dfL = df[df.Type == 'L']\n",
        "dfH = df[df.Type == 'H']\n",
        "\n",
        "df.loc[cdr_range(df, 'L', 30, 36), 'CDR'] = 'L1'\n",
        "df.loc[cdr_range(df, 'L', 46, 55), 'CDR'] = 'L2'\n",
        "df.loc[cdr_range(df, 'L', 89, 96), 'CDR'] = 'L3'\n",
        "\n",
        "df.loc[cdr_range(df, 'H', 30, 35), 'CDR'] = 'H1'\n",
        "df.loc[cdr_range(df, 'H', 47, 58), 'CDR'] = 'H2'\n",
        "df.loc[cdr_range(df, 'H', 93, 101), 'CDR'] = 'H3'\n",
        "\n",
        "df.to_csv('cdr_martin_residues.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "2HGBHTJrejCt",
        "colab": {}
      },
      "source": [
        "#@title CDR preprocessing\n",
        "\n",
        "dfr = pd.read_csv('cdr_martin_residues.csv')\n",
        "\n",
        "# display(dfm[dfm.pdb == '1a14'])\n",
        "# display(dfr[:500:10])\n",
        "\n",
        "data = []\n",
        "for (file, model, key, btype), dff in dfr.groupby(['File', 'Model', 'Key', 'Type']):\n",
        "\n",
        "  dff = dff.reset_index(drop=True)\n",
        "  item = dict(\n",
        "      File=file,\n",
        "      Model=model,\n",
        "      Key=key,\n",
        "      Type=btype,\n",
        "  )\n",
        "  data.append(item)\n",
        "\n",
        "  for bnum in (1, 2, 3):\n",
        "    cdr = f'{btype}{bnum}'\n",
        "    dffc = dff[dff.CDR == cdr]\n",
        "    item[f'Seq{bnum}'] = ''.join(dffc.Res)\n",
        "    item[f'Start{bnum}'] = dffc.index[0]\n",
        "    item[f'EndInc{bnum}'] = dffc.index[-1]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "# df = df.sort_values(['File', 'Model'])###\n",
        "# df = df.drop_duplicates(['Seq1', 'Seq2', 'Seq3'])\n",
        "df.to_csv('cdr_preprocessed.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRPsaKm0Rtf_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title CDR flattening\n",
        "\n",
        "dfp = pd.read_csv('cdr_preprocessed.csv')\n",
        "\n",
        "adff = []\n",
        "for bnum in (1, 2, 3):\n",
        "  dff = dfp[f'File,Model,Key,Type,Seq{bnum},Start{bnum},EndInc{bnum}'.split(',')]\n",
        "  dff = dff.rename(columns={\n",
        "      f'Seq{bnum}': 'Seq',\n",
        "      f'Start{bnum}': 'Start',\n",
        "      f'EndInc{bnum}': 'EndInc',\n",
        "  })\n",
        "  dff.insert(4, 'Region', bnum)\n",
        "  adff.append(dff)\n",
        "\n",
        "df = pd.concat(adff)\n",
        "df = df.sort_values(['File', 'Model', 'Type', 'Region'])\n",
        "df.to_csv('cdr_flattened.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK90e1zgUCse",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title CDR contact point refinement\n",
        "\n",
        "dfc = pd.read_csv('contacts_filtered.csv')\n",
        "dfr = pd.read_csv('cdr_preprocessed.csv')\n",
        "\n",
        "df = dfc.merge(dfr.rename(columns={'Key': 'BKey', 'Type': 'BType'}), on=['File', 'Model', 'BKey', 'BType'])\n",
        "\n",
        "df['CDR'] = 0\n",
        "df['CDR Start'] = 0\n",
        "df['CDR EndInc'] = 0\n",
        "for bnum in(1, 2, 3):\n",
        "  cond = (df.BIndex >= df[f'Start{bnum}']) & (df.BIndex <= df[f'EndInc{bnum}'])\n",
        "  df.loc[cond, 'CDR'] = bnum\n",
        "  df.loc[cond, 'CDR Start'] = df[f'Start{bnum}']\n",
        "  df.loc[cond, 'CDR EndInc'] = df[f'EndInc{bnum}']\n",
        "  df = df.drop(columns=[f'Seq{bnum}', f'Start{bnum}', f'EndInc{bnum}'])\n",
        "\n",
        "df = df[df.CDR != 0]\n",
        "df.to_csv('contacts_cdr_filtered.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGLTjeIVwzHf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title VH-VL orientation calculation\n",
        "\n",
        "!wget -nc -O ABangle.tar.gz http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/downloads/abangle/\n",
        "!tar xsf ABangle.tar.gz\n",
        "!wget -nc https://zhanglab.ccmb.med.umich.edu/TM-align/TMalign.cpp\n",
        "!g++ -static -O3 -ffast-math -lm -o TMalign TMalign.cpp\n",
        "!mkdir -p /opt/bin\n",
        "!mv ./TMalign /opt/bin\n",
        "clear_output()\n",
        "\n",
        "!pdb_selchain -H,L all_structures/chothia/5ukq.pdb > AB.pdb\n",
        "!python2 ./ABangle/ABangle -i AB.pdb -usernumbered -target 5ukq -store n -png output.png -showinfo -msa -mr -seqid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZv8YAyZa5Uh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Feature assembly\n",
        "\n",
        "dfs = pd.read_csv('dssp_residues.csv')\n",
        "dfc = pd.read_csv('contacts_cdr_filtered.csv')\n",
        "\n",
        "data = []\n",
        "for (file, model, bkey, akey), dffc in dfc.groupby(['File', 'Model', 'BKey', 'AKey']):\n",
        "  \n",
        "  dffs = dfs[(dfs.File == file) & (dfs.Model == model)]\n",
        "\n",
        "  b_dffs = dffs[dffs.Key == bkey]\n",
        "  a_dffs = dffs[dffs.Key == akey]\n",
        "\n",
        "  print(file, len(dffc), len(dffs))\n",
        "  # print(file[:-4])\n",
        "\n",
        "  for i, row in dffc.iterrows():\n",
        "    bi = row.BIndex\n",
        "    b_secondary = b_dffs.iloc[bi - contact_buffer:bi + contact_buffer + 1]\n",
        "    ai = row.AIndex###\n",
        "    a_secondary = a_dffs.iloc[ai - contact_buffer:ai + contact_buffer + 1]\n",
        "    \n",
        "    if len(b_secondary) != contact_window_size or len(a_secondary) != contact_window_size:\n",
        "      print('Length mismatch')\n",
        "      continue\n",
        "    \n",
        "    if not np.all((b_secondary.Residue.values == list(row.BWindow)) & (a_secondary.Residue.values == list(row.AWindow))):\n",
        "      print('Residue mismatch')\n",
        "      continue\n",
        "\n",
        "    data.append(dict(\n",
        "        File=file,\n",
        "        Model=model,\n",
        "        Type=row.BType,\n",
        "        CDR=row.CDR,\n",
        "        CDR_S=row['CDR Start'],\n",
        "        CDR_EI=row['CDR EndInc'],\n",
        "        BKey=bkey,\n",
        "        BIndex=bi,\n",
        "        BWindow=row.BWindow,\n",
        "        BSec='|'.join(b_secondary.SS),\n",
        "        BSol='|'.join(str(round(f, 6)) for f in b_secondary.ASA),\n",
        "        AKey=row.AKey,\n",
        "        AIndex=ai,\n",
        "        AWindow=row.AWindow,\n",
        "        ASec='|'.join(a_secondary.SS),\n",
        "        ASol='|'.join(str(round(f, 6)) for f in a_secondary.ASA),\n",
        "    ))\n",
        "\n",
        "# dfmg = dfm.rename(columns={'file': 'File','model': 'Model'})\n",
        "# dfmg['resolution'] = pd.to_numeric(dfmg.resolution, errors='coerce')\n",
        "# df['Res'] = dfmg.resolution\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df = df[(df.BWindow.str.len() == contact_window_size) & (df.AWindow.str.len() == contact_window_size)]\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates(['BWindow', 'AWindow'])\n",
        "df.to_csv('features_contacts.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqMM9KBZw7lv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title CDR window collection\n",
        "\n",
        "dfc = pd.read_csv('cdr_flattened.csv')\n",
        "\n",
        "dfd = pd.read_csv('docked_secondary.csv')\n",
        "dfd = dfd[dfd.Compact.str.len() >= 9]\n",
        "\n",
        "dfcd = dfc.merge(dfd, on=['File', 'Model', 'Key'])\n",
        "\n",
        "data = []\n",
        "for i, row in dfcd.iterrows():\n",
        "  if i % 100 == 0:\n",
        "    print(row.File)\n",
        "\n",
        "  for index in range(row.Start, row.EndInc + 1):\n",
        "    window = row.Compact[index - contact_buffer:index + contact_buffer + 1]\n",
        "    ss_window = '|'.join(row.SS.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "    asa_window = '|'.join(row.ASA.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "\n",
        "    data.append(dict(\n",
        "        File=row.File,\n",
        "        Model=row.Model,\n",
        "        Type=row.Type,\n",
        "        CDR=row.Region,\n",
        "        CDR_S=row.Start,\n",
        "        CDR_EI=row.EndInc,\n",
        "        BKey=row.Key,\n",
        "        BIndex=index,\n",
        "        BWindow=window,\n",
        "        BSec=ss_window,\n",
        "        BSol=asa_window,\n",
        "    ))\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df = df[df.BWindow.str.len() == contact_window_size]\n",
        "df = df.dropna()\n",
        "df.to_csv('windows_cdr.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkNQpM1JBDHT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Antigen window collection\n",
        "\n",
        "dfd = pd.read_csv('docked_secondary.csv')\n",
        "dfd = dfd[dfd.Compact.str.len() >= 9]\n",
        "\n",
        "for file, model, hk, lk in dfm[['file', 'model', 'Hchain', 'Lchain']].sort_values('file').values:\n",
        "  print(file)\n",
        "\n",
        "  dfd = dfd[(dfd.File != file) | (dfd.Model != model) | ~dfd.Key.isin((hk, lk))]\n",
        "\n",
        "  print(len(dfd))\n",
        "\n",
        "data = []\n",
        "for i, row in dfd.iterrows():\n",
        "  if i % 100 == 0:\n",
        "    print(row.File)\n",
        "\n",
        "  for index in range(contact_buffer, len(row.Compact) - contact_buffer):\n",
        "    window = row.Compact[index - contact_buffer:index + contact_buffer + 1]\n",
        "    ss_window = '|'.join(row.SS.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "    asa_window = '|'.join(row.ASA.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "\n",
        "    data.append(dict(\n",
        "        File=row.File,\n",
        "        Model=row.Model,\n",
        "        AKey=row.Key,\n",
        "        AIndex=index,\n",
        "        AWindow=window,\n",
        "        ASec=ss_window,\n",
        "        ASol=asa_window,\n",
        "    ))\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df = df[df.AWindow.str.len() == contact_window_size]\n",
        "df = df.dropna()\n",
        "# df = df.drop_duplicates(['BWindow', 'AWindow'])\n",
        "df.to_csv('windows_ag.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHfE4x4N7O05",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Full window collection\n",
        "\n",
        "dfd = pd.read_csv('docked_secondary.csv')\n",
        "dfd = dfd[dfd.Compact.str.len() >= 9]\n",
        "\n",
        "data = []\n",
        "for i, row in dfd.iterrows():\n",
        "  if i % 100 == 0:\n",
        "    print(row.File)\n",
        "\n",
        "  for index in range(contact_buffer, len(row.Compact) - contact_buffer):\n",
        "    window = row.Compact[index - contact_buffer:index + contact_buffer + 1]\n",
        "    ss_window = '|'.join(row.SS.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "    asa_window = '|'.join(row.ASA.split('|')[index - contact_buffer:index + contact_buffer + 1])\n",
        "\n",
        "    data.append(dict(\n",
        "        File=row.File,\n",
        "        Model=row.Model,\n",
        "        AKey=row.Key,\n",
        "        AIndex=index,\n",
        "        AWindow=window,\n",
        "        ASec=ss_window,\n",
        "        ASol=asa_window,\n",
        "    ))\n",
        "\n",
        "clear_output()\n",
        "df = pd.DataFrame(data)\n",
        "df = df[df.AWindow.str.len() == contact_window_size]\n",
        "df = df.dropna()\n",
        "# df = df.drop_duplicates(['BWindow', 'AWindow'])\n",
        "df.to_csv('windows_all.csv', index=False)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}